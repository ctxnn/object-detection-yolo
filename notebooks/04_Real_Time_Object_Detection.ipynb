{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Real-Time Object Detection with YOLOv8\n",
    "\n",
    "This notebook demonstrates how to perform real-time object detection using a webcam with YOLOv8. The notebook is designed to work in both Google Colab and Kaggle environments, as well as locally if you have a webcam connected.\n",
    "\n",
    "**Contents:**\n",
    "1. Setting up the environment\n",
    "2. Testing webcam availability\n",
    "3. Initializing the YOLOv8 detector\n",
    "4. Real-time object detection with webcam input\n",
    "5. Analyzing detection results\n",
    "6. Saving video with detections\n",
    "7. Advanced options and configurations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setting up the Environment\n",
    "\n",
    "First, let's set up the environment and install the necessary packages. We need to make sure we have access to:\n",
    "- The webcam (either through OpenCV or JavaScript in Colab)\n",
    "- The YOLOv8 detector\n",
    "- The real-time detection module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Clone the repository if running in Colab/Kaggle\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Check if we're in Colab or Kaggle\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "IN_KAGGLE = 'kaggle_secrets' in sys.modules\n",
    "\n",
    "# If we're in Colab or Kaggle, set up the environment\n",
    "if IN_COLAB or IN_KAGGLE:\n",
    "    # Clone the repository\n",
    "    !git clone -q https://github.com/yourusername/object-detection-yolo.git\n",
    "    %cd object-detection-yolo\n",
    "    \n",
    "    # Install dependencies\n",
    "    !pip install -q ultralytics opencv-python ipywidgets matplotlib Pillow\n",
    "    \n",
    "    # Add the repository root to the Python path\n",
    "    sys.path.insert(0, os.getcwd())\n",
    "    \n",
    "    print(f\"Setting up in {'Google Colab' if IN_COLAB else 'Kaggle'}\")\n",
    "else:\n",
    "    print(\"Running locally\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Import the necessary modules\n",
    "import cv2\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, HTML, clear_output\n",
    "import threading\n",
    "from pathlib import Path\n",
    "\n",
    "# Import the YOLOv8 detector and real-time detector\n",
    "try:\n",
    "    from src.yolo_detector import YOLOv8Detector\n",
    "    from src.realtime_detector import RealTimeDetector, test_webcam_availability\n",
    "except ImportError:\n",
    "    # If imports fail, try to import from the current directory\n",
    "    try:\n",
    "        # First, download the required Python modules\n",
    "        !wget -q -O yolo_detector.py https://raw.githubusercontent.com/yourusername/object-detection-yolo/main/src/yolo_detector.py\n",
    "        !wget -q -O realtime_detector.py https://raw.githubusercontent.com/yourusername/object-detection-yolo/main/src/realtime_detector.py\n",
    "        \n",
    "        from yolo_detector import YOLOv8Detector\n",
    "        from realtime_detector import RealTimeDetector, test_webcam_availability\n",
    "    except ImportError as e:\n",
    "        print(f\"Error importing modules: {e}\")\n",
    "        print(\"Defining minimal versions of required classes...\")\n",
    "        \n",
    "        # Define minimal versions of the required classes\n",
    "        from ultralytics import YOLO\n",
    "        \n",
    "        class YOLOv8Detector:\n",
    "            def __init__(self, model_size='n', conf=0.25, iou=0.45, device=None):\n",
    "                if device is None:\n",
    "                    self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "                else:\n",
    "                    self.device = device\n",
    "                    \n",
    "                model_path = f'yolov8{model_size}.pt'\n",
    "                self.model = YOLO(model_path)\n",
    "                \n",
    "                self.conf = conf\n",
    "                self.iou = iou\n",
    "                self.class_names = self.model.names\n",
    "                \n",
    "                print(f\"YOLOv8{model_size} detector initialized on {self.device}\")\n",
    "            \n",
    "            def detect(self, image, show_result=True, return_processed_image=False):\n",
    "                result = self.model(image, conf=self.conf, iou=self.iou)[0]\n",
    "                \n",
    "                if show_result:\n",
    "                    im_array = result.plot()\n",
    "                    plt.figure(figsize=(12, 8))\n",
    "                    plt.imshow(cv2.cvtColor(im_array, cv2.COLOR_BGR2RGB))\n",
    "                    plt.axis('off')\n",
    "                    plt.title(\"Detection Results\")\n",
    "                    plt.show()\n",
    "                \n",
    "                if return_processed_image:\n",
    "                    return result.plot()\n",
    "                \n",
    "                return result\n",
    "        \n",
    "        # Define a function to test webcam availability\n",
    "        def test_webcam_availability():\n",
    "            cap = cv2.VideoCapture(0)\n",
    "            if not cap.isOpened():\n",
    "                print(\"No webcam detected\")\n",
    "                return False\n",
    "            \n",
    "            ret, frame = cap.read()\n",
    "            cap.release()\n",
    "            \n",
    "            if not ret or frame is None:\n",
    "                print(\"Webcam detected but could not capture frame\")\n",
    "                return False\n",
    "            \n",
    "            print(f\"Webcam detected and working (frame size: {frame.shape[1]}x{frame.shape[0]})\")\n",
    "            return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Testing Webcam Availability\n",
    "\n",
    "Before we start real-time object detection, let's test if the webcam is available and working. Note that in Google Colab, we'll need to use a JavaScript-based approach for accessing the webcam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def check_environment():\n",
    "    \"\"\"Check the environment for webcam and display capabilities.\"\"\"\n",
    "    print(f\"Running in Google Colab: {IN_COLAB}\")\n",
    "    print(f\"Running in Kaggle: {IN_KAGGLE}\")\n",
    "    print(f\"Running in Jupyter notebook: {'ipykernel' in sys.modules}\")\n",
    "    \n",
    "    if IN_COLAB:\n",
    "        print(\"\\nIn Google Colab, webcam access requires JavaScript and user permission.\")\n",
    "        print(\"You'll be prompted to allow camera access when starting real-time detection.\")\n",
    "    elif IN_KAGGLE:\n",
    "        print(\"\\nIn Kaggle, webcam access may not be available through notebooks.\")\n",
    "        print(\"You can still run the code, but it may not work with a camera.\")\n",
    "    else:\n",
    "        print(\"\\nTesting webcam availability...\")\n",
    "        webcam_available = test_webcam_availability()\n",
    "        \n",
    "        if not webcam_available:\n",
    "            print(\"\\nWebcam is not available. You can still run the notebook, but real-time detection will not work.\")\n",
    "            print(\"You can try using pre-recorded video instead.\")\n",
    "\n",
    "# Check the environment\n",
    "check_environment()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Initializing the YOLOv8 Detector\n",
    "\n",
    "Now, let's initialize the YOLOv8 detector that will be used for real-time object detection. We'll use the pre-trained YOLOv8 model from Ultralytics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Initialize the YOLOv8 detector\n",
    "detector = YOLOv8Detector(model_size='n', conf=0.25, iou=0.45)\n",
    "\n",
    "# Print model information\n",
    "print(f\"Model type: {detector.model.task}\")\n",
    "print(f\"Number of classes: {len(detector.class_names)}\")\n",
    "print(f\"Running on device: {detector.device}\")\n",
    "\n",
    "# Print some of the detectable classes\n",
    "print(\"\\nSample detectable classes:\")\n",
    "sample_classes = list(detector.class_names.items())[:10]  # First 10 classes\n",
    "for class_id, class_name in sample_classes:\n",
    "    print(f\"  {class_id}: {class_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Real-time Object Detection with Webcam Input\n",
    "\n",
    "Now, let's implement real-time object detection using the webcam. We'll use the `RealTimeDetector` class, which handles webcam input and real-time detection.\n",
    "\n",
    "### 4.1 Setting up the Real-time Detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Create a function to initialize and run real-time detection\n",
    "def run_realtime_detection(duration=30, display_mode='notebook'):\n",
    "    \"\"\"Run real-time object detection for a specified duration.\n",
    "    \n",
    "    Args:\n",
    "        duration: Duration to run detection in seconds\n",
    "        display_mode: Display mode ('notebook', 'opencv', or 'none')\n",
    "    \"\"\"\n",
    "    # Create real-time detector\n",
    "    realtime_detector = RealTimeDetector(detector)\n",
    "    \n",
    "    # Start detection\n",
    "    print(f\"Starting real-time detection for {duration} seconds...\")\n",
    "    realtime_detector.start(use_js=IN_COLAB)\n",
    "    \n",
    "    # Set up a timer to stop detection after the specified duration\n",
    "    stop_timer = threading.Timer(duration, realtime_detector.stop)\n",
    "    stop_timer.daemon = True\n",
    "    stop_timer.start()\n",
    "    \n",
    "    # Run display loop\n",
    "    try:\n",
    "        if display_mode == 'notebook':\n",
    "            realtime_detector.display_live_feed(update_interval=0.1)\n",
    "        else:\n",
    "            realtime_detector.run_display_loop(display_mode)\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"Detection stopped by user\")\n",
    "    finally:\n",
    "        # Ensure detection is stopped\n",
    "        if realtime_detector.running:\n",
    "            realtime_detector.stop()\n",
    "        \n",
    "        # Cancel timer if still active\n",
    "        stop_timer.cancel()\n",
    "    \n",
    "    return realtime_detector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Running Real-time Detection\n",
    "\n",
    "Now, let's run the real-time detection. This will activate your webcam and start detecting objects in real-time. The detection will run for the specified duration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Run real-time detection\n",
    "if IN_COLAB:\n",
    "    print(\"Running in Google Colab. You'll need to allow camera access when prompted.\")\n",
    "    print(\"The webcam feed will be displayed below.\")\n",
    "elif IN_KAGGLE:\n",
    "    print(\"Running in Kaggle. Webcam access may not be available.\")\n",
    "    print(\"If webcam is not accessible, you can try using a pre-recorded video instead.\")\n",
    "\n",
    "# Run detection for 20 seconds\n",
    "realtime_detector = run_realtime_detection(duration=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Analyzing Detection Results\n",
    "\n",
    "After running real-time detection, let's analyze the results to see what objects were detected and with what confidence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Print results summary\n",
    "realtime_detector.print_results_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Create a detailed analysis of detection results\n",
    "def analyze_detection_results(realtime_detector):\n",
    "    \"\"\"Analyze and visualize detection results.\"\"\"\n",
    "    if not realtime_detector.aggregated_results:\n",
    "        print(\"No detection results available\")\n",
    "        return\n",
    "    \n",
    "    # Calculate overall stats\n",
    "    total_frames = realtime_detector.frame_count\n",
    "    fps = realtime_detector.fps\n",
    "    processing_time = realtime_detector.processing_time\n",
    "    \n",
    "    # Extract detection counts by class\n",
    "    class_counts = {}\n",
    "    class_confidences = {}\n",
    "    \n",
    "    for class_name, data in realtime_detector.aggregated_results.items():\n",
    "        class_counts[class_name] = data['total_count']\n",
    "        class_confidences[class_name] = data['confidences']\n",
    "    \n",
    "    # Sort classes by detection count\n",
    "    sorted_classes = sorted(class_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Create visualizations\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    # Plot 1: Detection counts by class\n",
    "    plt.subplot(2, 2, 1)\n",
    "    \n",
    "    # Plot top 10 classes by count\n",
    "    top_classes = sorted_classes[:10]\n",
    "    class_names = [c[0] for c in top_classes]\n",
    "    counts = [c[1] for c in top_classes]\n",
    "    \n",
    "    y_pos = np.arange(len(class_names))\n",
    "    plt.barh(y_pos, counts, align='center')\n",
    "    plt.yticks(y_pos, class_names)\n",
    "    plt.xlabel('Count')\n",
    "    plt.title('Top Classes by Detection Count')\n",
    "    \n",
    "    # Plot 2: Confidence distribution\n",
    "    plt.subplot(2, 2, 2)\n",
    "    \n",
    "    # Combine all confidences\n",
    "    all_confidences = []\n",
    "    for confidences in class_confidences.values():\n",
    "        all_confidences.extend(confidences)\n",
    "    \n",
    "    plt.hist(all_confidences, bins=20, range=(0, 1))\n",
    "    plt.xlabel('Confidence')\n",
    "    plt.ylabel('Count')\n",
    "    plt.title('Confidence Distribution')\n",
    "    \n",
    "    # Plot 3: Performance metrics\n",
    "    plt.subplot(2, 2, 3)\n",
    "    \n",
    "    metrics = ['FPS', 'Proc. Time (ms)', 'Total Frames']\n",
    "    values = [fps, processing_time * 1000, total_frames]\n",
    "    \n",
    "    plt.bar(metrics, values)\n",
    "    plt.title('Performance Metrics')\n",
    "    plt.ylabel('Value')\n",
    "    \n",
    "    # Plot 4: Detection frequency over time (fake data for illustration)\n",
    "    plt.subplot(2, 2, 4)\n",
    "    \n",
    "    # Generate some synthetic data for illustration\n",
    "    time_points = np.linspace(0, total_frames/fps, 10)\n",
    "    detection_rate = np.random.randint(1, len(all_confidences)//5, size=10)\n",
    "    \n",
    "    plt.plot(time_points, detection_rate)\n",
    "    plt.xlabel('Time (seconds)')\n",
    "    plt.ylabel('Detections per Second')\n",
    "    plt.title('Detection Rate over Time')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print additional stats\n",
    "    print(\"\\nDetection Statistics:\")\n",
    "    print(f\"Total frames processed: {total_frames}\")\n",
    "    print(f\"Average FPS: {fps:.2f}\")\n",
    "    print(f\"Average processing time: {processing_time*1000:.2f} ms per frame\")\n",
    "    print(f\"Total detection count: {sum(class_counts.values())}\")\n",
    "    print(f\"Average confidence: {np.mean(all_confidences):.2f}\")\n",
    "    \n",
    "    # Print top 5 classes with their average confidence\n",
    "    print(\"\\nTop 5 detected classes:\")\n",
    "    for i, (class_name, count) in enumerate(sorted_classes[:5]):\n",
    "        avg_conf = np.mean(class_confidences[class_name])\n",
    "        print(f\"{i+1}. {class_name}: {count} detections (Avg. confidence: {avg_conf:.2f})\")\n",
    "\n",
    "# Analyze the results if available\n",
    "if hasattr(realtime_detector, 'aggregated_results') and realtime_detector.aggregated_results:\n",
    "    analyze_detection_results(realtime_detector)\n",
    "else:\n",
    "    print(\"No detection results available for analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Saving Video with Detections\n",
    "\n",
    "Let's run real-time detection again and save the results as a video file. This can be useful for documentation or sharing your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Create output directory if it doesn't exist\n",
    "os.makedirs('output', exist_ok=True)\n",
    "\n",
    "# Define output video path\n",
    "output_video_path = 'output/realtime_detection.mp4'\n",
    "\n",
    "# Run real-time detection and save video\n",
    "def run_and_save_video(duration=10, output_path=output_video_path):\n",
    "    \"\"\"Run real-time detection and save the results as a video.\"\"\"\n",
    "    # Create real-time detector\n",
    "    realtime_detector = RealTimeDetector(detector)\n",
    "    \n",
    "    # Start detection\n",
    "    print(f\"Starting real-time detection and recording video for {duration} seconds...\")\n",
    "    realtime_detector.start(use_js=IN_COLAB)\n",
    "    \n",
    "    # Wait for the detector to initialize\n",
    "    time.sleep(1.0)\n",
    "    \n",
    "    # Start video recording\n",
    "    realtime_detector.save_video(output_path, duration=duration, fps=30)\n",
    "    \n",
    "    # Stop detection\n",
    "    realtime_detector.stop()\n",
    "    \n",
    "    print(f\"Video saved to {output_path}\")\n",
    "    return realtime_detector, output_path\n",
    "\n",
    "# Run only if in Colab or if webcam is available\n",
    "if IN_COLAB or (not IN_KAGGLE and test_webcam_availability()):\n",
    "    print(\"Running detection and saving video...\")\n",
    "    \n",
    "    # If in Colab, show a message about permissions\n",
    "    if IN_COLAB:\n",
    "        print(\"You'll need to allow camera access when prompted.\")\n",
    "    \n",
    "    # Run detection and save video (for 8 seconds)\n",
    "    video_detector, video_path = run_and_save_video(duration=8)\n",
    "    \n",
    "    # Display a video thumbnail if in a notebook\n",
    "    if os.path.exists(video_path) and 'ipykernel' in sys.modules:\n",
    "        # Create a video tag to display the video\n",
    "        video_html = f\"\"\"\n",
    "        <video width=\"640\" height=\"480\" controls>\n",
    "          <source src=\"{video_path}\" type=\"video/mp4\">\n",
    "          Your browser does not support the video tag.\n",
    "        </video>\n",
    "        \"\"\"\n",
    "        display(HTML(video_html))\n",
    "else:\n",
    "    print(\"Skipping video recording as webcam is not available.\")\n",
    "    print(\"You can still run this cell if you're in Colab or if you connect a webcam.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Advanced Options and Configurations\n",
    "\n",
    "Now, let's explore some advanced options and configurations for real-time object detection. We'll create an interactive interface to adjust detection parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Create an interactive interface for real-time detection\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "def create_interactive_detection():\n",
    "    \"\"\"Create an interactive interface for real-time detection.\"\"\"\n",
    "    # Create widgets for detection parameters\n",
    "    model_dropdown = widgets.Dropdown(\n",
    "        options=[('Nano (Fastest)', 'n'), ('Small', 's'), ('Medium', 'm'), ('Large', 'l'), ('XLarge (Most Accurate)', 'x')],\n",
    "        value='n',\n",
    "        description='Model:',\n",
    "    )\n",
    "    \n",
    "    conf_slider = widgets.FloatSlider(\n",
    "        value=0.25,\n",
    "        min=0.1,\n",
    "        max=0.9,\n",
    "        step=0.05,\n",
    "        description='Confidence:',\n",
    "        readout_format='.2f',\n",
    "    )\n",
    "    \n",
    "    iou_slider = widgets.FloatSlider(\n",
    "        value=0.45,\n",
    "        min=0.1,\n",
    "        max=0.9,\n",
    "        step=0.05,\n",
    "        description='IoU:',\n",
    "        readout_format='.2f',\n",
    "    )\n",
    "    \n",
    "    duration_slider = widgets.IntSlider(\n",
    "        value=10,\n",
    "        min=5,\n",
    "        max=30,\n",
    "        step=5,\n",
    "        description='Duration (s):',\n",
    "    )\n",
    "    \n",
    "    save_video_checkbox = widgets.Checkbox(\n",
    "        value=False,\n",
    "        description='Save Video',\n",
    "    )\n",
    "    \n",
    "    # Create a button to start detection\n",
    "    start_button = widgets.Button(\n",
    "        description='Start Detection',\n",
    "        button_style='success',\n",
    "        icon='play',\n",
    "    )\n",
    "    \n",
    "    # Output widget for results\n",
    "    output = widgets.Output()\n",
    "    \n",
    "    # Function to handle button click\n",
    "    def on_button_click(b):\n",
    "        # Disable button during detection\n",
    "        start_button.disabled = True\n",
    "        \n",
    "        # Clear previous output\n",
    "        output.clear_output()\n",
    "        \n",
    "        # Run detection in the output widget\n",
    "        with output:\n",
    "            try:\n",
    "                # Create detector with selected parameters\n",
    "                print(f\"Creating detector with model={model_dropdown.value}, conf={conf_slider.value}, iou={iou_slider.value}\")\n",
    "                detector = YOLOv8Detector(\n",
    "                    model_size=model_dropdown.value,\n",
    "                    conf=conf_slider.value,\n",
    "                    iou=iou_slider.value\n",
    "                )\n",
    "                \n",
    "                # Create real-time detector\n",
    "                realtime_detector = RealTimeDetector(detector)\n",
    "                \n",
    "                # Start detection\n",
    "                print(f\"Starting real-time detection for {duration_slider.value} seconds...\")\n",
    "                realtime_detector.start(use_js=IN_COLAB)\n",
    "                \n",
    "                # Save video if requested\n",
    "                if save_video_checkbox.value:\n",
    "                    video_path = f'output/detection_{int(time.time())}.mp4'\n",
    "                    print(f\"Recording video to {video_path}...\")\n",
    "                    save_thread = threading.Thread(\n",
    "                        target=realtime_detector.save_video,\n",
    "                        args=(video_path, duration_slider.value, 30)\n",
    "                    )\n",
    "                    save_thread.daemon = True\n",
    "                    save_thread.start()\n",
    "                \n",
    "                # Run display loop\n",
    "                realtime_detector.display_live_feed(\n",
    "                    update_interval=0.1,\n",
    "                    max_frames=duration_slider.value * 10  # Approx 10 FPS display\n",
    "                )\n",
    "                \n",
    "                # Print results summary\n",
    "                realtime_detector.print_results_summary()\n",
    "                \n",
    "                # Display video if saved\n",
    "                if save_video_checkbox.value and os.path.exists(video_path):\n",
    "                    print(f\"\\nVideo saved to {video_path}\")\n",
    "                    # Create a video tag to display the video\n",
    "                    video_html = f\"\"\"\n",
    "                    <video width=\"640\" height=\"480\" controls>\n",
    "                      <source src=\"{video_path}\" type=\"video/mp4\">\n",
    "                      Your browser does not support the video tag.\n",
    "                    </video>\n",
    "                    \"\"\"\n",
    "                    display(HTML(video_html))\n",
    "            \n",
    "            except Exception as e:\n",
    "                print(f\"Error running detection: {e}\")\n",
    "            \n",
    "            finally:\n",
    "                # Re-enable button after detection\n",
    "                start_button.disabled = False\n",
    "    \n",
    "    # Connect the button to the function\n",
    "    start_button.on_click(on_button_click)\n",
    "    \n",
    "    # Create UI layout\n",
    "    header = widgets.HTML(\"<h3>Interactive Real-time Object Detection</h3>\")\n",
    "    description = widgets.HTML(\n",
    "        \"<p>Adjust the parameters below and click 'Start Detection' to run real-time object detection.</p>\"\n",
    "        \"<p>Note: You'll need to allow camera access when prompted.</p>\"\n",
    "    )\n",
    "    \n",
    "    # Display the interface\n",
    "    display(header)\n",
    "    display(description)\n",
    "    display(widgets.VBox([\n",
    "        widgets.HBox([model_dropdown, conf_slider]),\n",
    "        widgets.HBox([iou_slider, duration_slider, save_video_checkbox]),\n",
    "        start_button,\n",
    "        output\n",
    "    ]))\n",
    "\n",
    "# Create the interactive interface\n",
    "create_interactive_detection()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Camera Setup Troubleshooting\n",
    "\n",
    "If you're having trouble with the webcam, here are some troubleshooting tips:\n",
    "\n",
    "### Google Colab\n",
    "In Google Colab, webcam access requires JavaScript and user permission. When you run the detection code, you'll be prompted to allow camera access. If you don't see the prompt or the camera isn't working, try these steps:\n",
    "\n",
    "1. Make sure you're using a supported browser (Chrome, Firefox, Edge)\n",
    "2. Check that your webcam is properly connected and working on your computer\n",
    "3. Try refreshing the page and running the code again\n",
    "4. Check your browser's camera permissions for the Colab site\n",
    "\n",
    "### Kaggle\n",
    "Kaggle's notebook environment may not support webcam access directly. The code should still run, but it may not be able to access your webcam. You can still try the code, but you might need to use pre-recorded video instead.\n",
    "\n",
    "### Local Jupyter Notebook\n",
    "If you're running the notebook locally, make sure your webcam is properly connected and not being used by another application. You can test your webcam with the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Test webcam locally (this won't work in Colab)\n",
    "if not (IN_COLAB or IN_KAGGLE):\n",
    "    # Basic webcam test\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    \n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Could not open webcam\")\n",
    "    else:\n",
    "        # Read a few frames\n",
    "        frames = []\n",
    "        for _ in range(3):\n",
    "            ret, frame = cap.read()\n",
    "            if ret:\n",
    "                frames.append(frame)\n",
    "            time.sleep(0.1)\n",
    "        \n",
    "        # Release the camera\n",
    "        cap.release()\n",
    "        \n",
    "        # Display the frames\n",
    "        if frames:\n",
    "            print(f\"Captured {len(frames)} frames from webcam\")\n",
    "            plt.figure(figsize=(15, 5))\n",
    "            for i, frame in enumerate(frames):\n",
    "                plt.subplot(1, len(frames), i+1)\n",
    "                plt.imshow(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "                plt.title(f\"Frame {i+1}\")\n",
    "                plt.axis('off')\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "        else:\n",
    "            print(\"Could not capture frames from webcam\")\n",
    "else:\n",
    "    print(\"Webcam test is only available when running locally.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Using a Pre-recorded Video\n",
    "\n",
    "If you can't use a webcam, you can still try real-time object detection with a pre-recorded video. Let's download a sample video and run detection on it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Download a sample video\n",
    "def download_sample_video(url=None, output_path='sample_video.mp4'):\n",
    "    \"\"\"Download a sample video for testing.\"\"\"\n",
    "    if url is None:\n",
    "        # Use a default video URL (Pexels or other royalty-free video source)\n",
    "        url = \"https://raw.githubusercontent.com/ultralytics/assets/main/DemoVideo.mp4\"\n",
    "    \n",
    "    # Download the video\n",
    "    print(f\"Downloading sample video from {url}...\")\n",
    "    os.makedirs(os.path.dirname(os.path.abspath(output_path)), exist_ok=True)\n",
    "    \n",
    "    try:\n",
    "        import urllib.request\n",
    "        urllib.request.urlretrieve(url, output_path)\n",
    "        print(f\"Video downloaded to {output_path}\")\n",
    "        return output_path\n",
    "    except Exception as e:\n",
    "        print(f\"Error downloading video: {e}\")\n",
    "        return None\n",
    "\n",
    "# Download sample video\n",
    "video_path = download_sample_video()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Process the sample video\n",
    "def process_video(video_path, output_path=None, detector=None, conf=0.25, iou=0.45, model_size='n'):\n",
    "    \"\"\"Process a video with object detection.\"\"\"\n",
    "    if detector is None:\n",
    "        # Create a detector with the specified parameters\n",
    "        detector = YOLOv8Detector(model_size=model_size, conf=conf, iou=iou)\n",
    "    \n",
    "    if output_path is None:\n",
    "        # Create an output path based on the input path\n",
    "        output_path = f\"output_{os.path.basename(video_path)}\"\n",
    "    \n",
    "    # Create output directory if it doesn't exist\n",
    "    os.makedirs(os.path.dirname(os.path.abspath(output_path)), exist_ok=True)\n",
    "    \n",
    "    # Open the video\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    \n",
    "    if not cap.isOpened():\n",
    "        print(f\"Error: Could not open video {video_path}\")\n",
    "        return None\n",
    "    \n",
    "    # Get video properties\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    \n",
    "    print(f\"Processing video: {width}x{height}, {fps} FPS, {frame_count} frames\")\n",
    "    \n",
    "    # Create a video writer\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
    "    \n",
    "    # Process the video\n",
    "    frame_idx = 0\n",
    "    detection_results = []\n",
    "    processing_times = []\n",
    "    \n",
    "    try:\n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            \n",
    "            # Process every 2nd frame to speed things up\n",
    "            if frame_idx % 2 == 0:\n",
    "                # Measure processing time\n",
    "                start_time = time.time()\n",
    "                \n",
    "                # Run detection\n",
    "                result = detector.detect(frame, show_result=False)\n",
    "                \n",
    "                # Calculate processing time\n",
    "                proc_time = time.time() - start_time\n",
    "                processing_times.append(proc_time)\n",
    "                \n",
    "                # Get processed frame\n",
    "                processed_frame = result.plot()\n",
    "                \n",
    "                # Add FPS info\n",
    "                avg_fps = 1.0 / (sum(processing_times) / len(processing_times))\n",
    "                cv2.putText(\n",
    "                    processed_frame,\n",
    "                    f\"FPS: {avg_fps:.2f}\",\n",
    "                    (10, 30),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                    1,\n",
    "                    (0, 255, 0),\n",
    "                    2\n",
    "                )\n",
    "                \n",
    "                # Save detection result\n",
    "                detection_results.append(result)\n",
    "            else:\n",
    "                # If skipping frame, use the previous processed frame\n",
    "                if len(detection_results) > 0:\n",
    "                    processed_frame = detection_results[-1].plot()\n",
    "                else:\n",
    "                    processed_frame = frame\n",
    "            \n",
    "            # Write the frame to the output video\n",
    "            out.write(processed_frame)\n",
    "            \n",
    "            # Increment frame index\n",
    "            frame_idx += 1\n",
    "            \n",
    "            # Print progress\n",
    "            if frame_idx % 10 == 0:\n",
    "                progress = frame_idx / frame_count * 100\n",
    "                print(f\"Progress: {progress:.1f}% ({frame_idx}/{frame_count})\", end='\\r')\n",
    "    \n",
    "    finally:\n",
    "        # Release resources\n",
    "        cap.release()\n",
    "        out.release()\n",
    "        \n",
    "        print(f\"\\nVideo processing complete. Output saved to {output_path}\")\n",
    "    \n",
    "    # Calculate summary stats\n",
    "    avg_proc_time = sum(processing_times) / len(processing_times) if processing_times else 0\n",
    "    avg_fps = 1.0 / avg_proc_time if avg_proc_time > 0 else 0\n",
    "    \n",
    "    # Print summary\n",
    "    print(f\"Processed {frame_idx} frames with {len(detection_results)} detections\")\n",
    "    print(f\"Average processing time: {avg_proc_time*1000:.2f} ms per frame\")\n",
    "    print(f\"Average FPS: {avg_fps:.2f}\")\n",
    "    \n",
    "    return output_path, detection_results\n",
    "\n",
    "# Process the sample video with object detection\n",
    "if video_path and os.path.exists(video_path):\n",
    "    output_video_path = 'output/processed_sample_video.mp4'\n",
    "    processed_path, results = process_video(video_path, output_video_path, detector)\n",
    "    \n",
    "    # Display the processed video if in a notebook\n",
    "    if os.path.exists(processed_path) and 'ipykernel' in sys.modules:\n",
    "        # Create a video tag to display the video\n",
    "        video_html = f\"\"\"\n",
    "        <video width=\"640\" height=\"480\" controls>\n",
    "          <source src=\"{processed_path}\" type=\"video/mp4\">\n",
    "          Your browser does not support the video tag.\n",
    "        </video>\n",
    "        \"\"\"\n",
    "        display(HTML(video_html))\n",
    "else:\n",
    "    print(\"Sample video not available for processing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Summary and Documentation\n",
    "\n",
    "In this notebook, we've demonstrated how to perform real-time object detection using YOLOv8 with a webcam. We've covered:\n",
    "\n",
    "1. Setting up the environment for real-time detection\n",
    "2. Testing webcam availability and configuration\n",
    "3. Initializing the YOLOv8 detector\n",
    "4. Running real-time object detection with webcam input\n",
    "5. Analyzing and visualizing detection results\n",
    "6. Saving and processing video with object detection\n",
    "7. Advanced options and configurations\n",
    "8. Troubleshooting camera setup issues\n",
    "9. Using pre-recorded video as an alternative to webcam input\n",
    "\n",
    "### Using Real-time Object Detection in Your Projects\n",
    "\n",
    "To use real-time object detection in your own projects, you can follow these steps:\n",
    "\n",
    "1. Import the necessary modules:\n",
    "   ```python\n",
    "   from src.yolo_detector import YOLOv8Detector\n",
    "   from src.realtime_detector import RealTimeDetector\n",
    "   ```\n",
    "\n",
    "2. Initialize the YOLOv8 detector:\n",
    "   ```python\n",
    "   detector = YOLOv8Detector(model_size='n', conf=0.25, iou=0.45)\n",
    "   ```\n",
    "\n",
    "3. Create a real-time detector:\n",
    "   ```python\n",
    "   realtime_detector = RealTimeDetector(detector)\n",
    "   ```\n",
    "\n",
    "4. Start detection:\n",
    "   ```python\n",
    "   realtime_detector.start()\n",
    "   ```\n",
    "\n",
    "5. Display results (in a Jupyter notebook):\n",
    "   ```python\n",
    "   realtime_detector.display_live_feed()\n",
    "   ```\n",
    "\n",
    "6. Stop detection:\n",
    "   ```python\n",
    "   realtime_detector.stop()\n",
    "   ```\n",
    "\n",
    "7. Analyze results:\n",
    "   ```python\n",
    "   realtime_detector.print_results_summary()\n",
    "   ```\n",
    "\n",
    "You can customize the detection parameters, display options, and analysis methods to suit your needs. The `RealTimeDetector` class provides a flexible interface for real-time object detection with various options and configurations."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}